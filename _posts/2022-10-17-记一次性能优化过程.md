---
title: 记一次性能优化过程，3个月优化为3天
date: 2022-10-17
categories: [课程]
tags: [性能优化]   
img_path: /assets/img/
---

事情起因是这样的，一天学长找到我说:"学弟啊，你有没有空啊。现在跑机器学习实验，跑3个月结果还跑不出来，你能不能帮我优化一下代码啊？”

我心想：“一次实验跑三个月，万一写了一点bug，实验不又得重头再来三个月，这也太令人头皮发麻了吧？“

于是我开始了实验代码优化之旅。

## 整体思路

仔细看了实验项目，代码量挺多的，一时间没有优化思路。

问了学长，目前所有实验执行都是单核CPU，没有多线程多进程。

那优化思路不就有了嘛——并行化，如果可以开多个进程同时跑实验，效率直接可以翻几十倍（当然最终受限于硬件资源）。

要代码并行化，要满足以下几个条件

- 有大量的、重复的、类似的任务

  >目前实验时间开销都主要用在聚类操作中，一次实验大概要做800w次聚类，平均一次聚类3s。

- 并行任务之间不能有依赖关系

  > 分析了代码，现有实现聚类与聚类之间有前后依赖关系，但是优化去掉依赖关系

因此想到可以把聚类运算给单独拿出来，用多线程聚类来提升效率。

多线程并行化跑大量任务，很容易就想到**MapReduce**计算框架。

- 将计算过程分为Map，Reduce两个过程。
- 将大任务分为多个子任务，提前准备好每个子任务的输入数据。
- Map过程多个Worker（线程、进程）执行执行，完成子任务。
- Reduce过程将所有子任务结果聚合，形成最终大任务结果。

那么整体的实现思路就是

1. 数据准备：输出聚类输入数据
2. 任务拆分：将聚类输入分为多个子任务
3. 多机聚类：多进程、多机器并行执行聚类
4. 结果合并：汇聚聚类结果得到最终结果

## 聚类数据输出

要跑并行化代码，首先要把任务所需要的输入数据准备好，即导出聚类输入数据。

可是测试了一下，发现把聚类数据导出就要几天时间。

对于数据导出，这是比较典型的IO密集型任务，没有复杂的CPU运算。

对于IO密接型任务的优化主要从两方面考虑

- 提升单次磁盘写入数量：

  - 仔细看了学长的代码，震惊的发现，写入文件居然没有带buffer，一次写一个字节也是一次IO操作。
  - 通过加上一个大buffer，大幅减少IO次数。

- 减少总体数据大小

  - 实验用到的聚类数据都是Float型，学长将Float转为字符形式然后写入文件。但是更优化的方法是转为二进制形式，相比于字符形式表示的Float，二进制空间减少接近4倍。
  - 根据计算，输出的数据总共有10TB，而服务器的磁盘可用容量只有7T，优化后输出数据为2.1TB。
  - 这期间还尝试过把数据先压缩后再写入磁盘，但发现压缩本身相较于磁盘IO更耗费时间，遂放弃。


![image-20221018132652938](2022-10-17-记一次性能优化过程.assets/image-20221018132652938.png)

虽然优化后，聚类输出速度有了很大的提升，但还远远不够。我就在想是不是聚类输出过程中有复杂的CPU运算。

尝试用[pyinstrument](https://github.com/joerick/pyinstrument)工具分析了代码的执行过程和每个过程的执行时间。

>Pyinstrument 是一个Python 分析器。 以可视化的形式帮助您优化代码，使其更快。 输出信息包含了记录时间、线程数、总耗时、单行代码耗时、CPU执行时间等信息。

这一分析就发现一个大问题，可视化结果如下图。

输出聚类函数也就是`_out_clustering_values`执行了311s，其中有137s的时间浪费在一个`unique`函数上。

![image-20221017221528909](2022-10-17-记一次性能优化过程.assets/image-20221017221528909.png)

仔细分析了对应的代码，`unique`函数每次都要对几百万的数据做去重，仅仅只为了计算聚类数（一般聚类数远小于聚类输入数据，比如100w数据 聚成128类）。这其实根本没有必要，完全可以把聚类数设为一个定值。果断将`unique`函数去掉，整体效率提升45%。

## 多机任务执行

有了聚类数据，写了一个python脚本将数据做拆分，接下来要实现聚类并行化。

动手写了第一版**并行化聚类**代码，功能点主要如下：

- 多进程：Python由于GIL（全局解释器锁)的存在，多线程没法真正意义上的并发执行，所以要用python多进程。这里选择了python官方库`multiprocessing`中的进程池管理多进程。
- 日志输出：由于任务执行过程很久，有必要输出任务执行中的日志。此外需要考虑多个进程同时读写一个日志文件的竞争问题，这里选择了`concurrent_log_handler`这个库实现多进程日志。
- 支持随时停止，启动：任务执行过程中可能由于各自原因失败了，要支持任务从失败的地方继续跑，这里解决思路是单个任务切分不要太大，这样也可以在任务启动后，新增更多的机器（单个任务小了，任务数量多了）
- 其他一些统计功能：可以查看进度、总任务数、支持测算时间、预计时间。

看了下实验室服务器有16个核，32个线程，效率应该可以翻32倍，理论上3个月的任务，3天应该可以跑完。

把代码部署到服务器上，开始跑代码，跑了接近一天，发现进度不如预期。

问了学长，实验室还可以再提供几台机器，可以在多机器上一起跑聚类。

这是就出现了一个问题，需要把聚类数据同步到多个机器上。这里有几个选择

1. 直接通过移动硬盘拷贝，把输入数据copy到其他机器上

   >不可行：当时正值10-1国庆期间，实验室管机房的老师都下班了，机房进不去。

2. 在其他机器上重新导出一份聚类输入数据

   >理论可行，但不是最优的：聚类数据生成存在存在一定随机性，多机导出没法保证聚类数据一致。另外，其他几台机器配置各不相同，有些机器硬盘容量只有500G，而整个数据有4.2T。这导致需要针对不同机器改代码，颇为繁琐且容易出错。

3. 其他机器到主机器上下载子任务，下载多少就执行多少

   >这是最终选择的方案，其他机器通过ssh下载主服务器上的任务数据，每下载一个子任务，就启动一个进程执行。这样屏蔽了各个机器的配置差异，且支持添加新机器，老机器下线。

于是在并行化聚类代码中，增加了ssh 远端拉取数据的代码，相当于获取输入数据有了两种方式，一种是从本地直接读取，一种是从远端通过网络拉取。

>这期间还尝试过很多种下载数据的方法
>
>- rsync 
>- scp 
>
>但这些命令方法没法和多进程脚本结合起来，且不好管理数据量，因此最后还是自己写了一份python代码，做更精细化的管理。



终于并行化脚本顺顺利利的跑起来了，**整个聚类过程从原来的3个月跑不出来，到现在3天跑出结果**。性能优化明显。

不过这只是整个实验的一小步，距离做完整个实验，似乎还有一大段路要走。

## 其他

在这次优化过程中，还学到了许多linux指令，用到了许多曾经学到过的知识

- 统计当前目录下文件的个数（包括子目录），用来统计任务总数和执行情况

  ```
  ls -lR| grep "^-" | wc -l
  ```

- 统计文件大小

  ```
  du -sh
  ```

- linux查看网络使用情况

  ```
  iftop -n
  ```

- linux查看磁盘IO情况

  ```
  iotop
  ```

- python 内存占用分析 [Memray](https://github.com/bloomberg/memray)

- python 耗时分析 [pyinstrument](https://github.com/joerick/pyinstrument)

  